{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ticker Linking Module Testing\n",
    "\n",
    "This notebook tests various functions in the ticker linking module to ensure they work correctly.\n",
    "\n",
    "**Note:** This notebook can run with or without a database connection. Set `USE_DATABASE = False` to use mock data.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database mode: DISABLED (using mock data)\n"
     ]
    }
   ],
   "source": [
    "# Configuration: Set to False to test without database\n",
    "USE_DATABASE = False\n",
    "\n",
    "print(f\"Database mode: {'ENABLED' if USE_DATABASE else 'DISABLED (using mock data)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/alex/market-pulse-v2\n"
     ]
    }
   ],
   "source": [
    "# Add project root to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Imports successful\n"
     ]
    }
   ],
   "source": [
    "# Import required modules\n",
    "import logging\n",
    "from datetime import UTC, datetime\n",
    "from pprint import pprint\n",
    "from unittest.mock import Mock\n",
    "\n",
    "from app.db.models import Article, Ticker\n",
    "from jobs.ingest.linker import TickerLinker, COMMON_WORD_TICKERS\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"âœ“ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Tickers from Database (or Mock Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Created 20 mock tickers for testing\n",
      "\n",
      "First 10 tickers:\n",
      "  WAR: some ETF\n",
      "  TSLA: Tesla, Inc.\n",
      "  NVDA: NVIDIA Corporation\n",
      "  MSFT: Microsoft Corporation\n",
      "  V: Visa Inc.\n",
      "  GOOGL: Alphabet Inc.\n",
      "  AMZN: Amazon.com, Inc.\n",
      "  META: Meta Platforms, Inc.\n",
      "  AMD: Advanced Micro Devices, Inc.\n",
      "  INTC: Intel Corporation\n"
     ]
    }
   ],
   "source": [
    "if USE_DATABASE:\n",
    "    # Load from database\n",
    "    from app.db.session import SessionLocal\n",
    "    \n",
    "    session = SessionLocal()\n",
    "    tickers = session.query(Ticker).all()\n",
    "    print(f\"âœ“ Loaded {len(tickers)} tickers from database\")\n",
    "else:\n",
    "    # Create mock tickers for testing\n",
    "    session = None\n",
    "    \n",
    "    mock_ticker_data = [\n",
    "        (\"WAR\", \"some ETF\"),\n",
    "        (\"TSLA\", \"Tesla, Inc.\"),\n",
    "        (\"NVDA\", \"NVIDIA Corporation\"),\n",
    "        (\"MSFT\", \"Microsoft Corporation\"),\n",
    "        (\"V\", \"Visa Inc.\"),\n",
    "        (\"GOOGL\", \"Alphabet Inc.\"),\n",
    "        (\"AMZN\", \"Amazon.com, Inc.\"),\n",
    "        (\"META\", \"Meta Platforms, Inc.\"),\n",
    "        (\"AMD\", \"Advanced Micro Devices, Inc.\"),\n",
    "        (\"INTC\", \"Intel Corporation\"),\n",
    "        (\"GME\", \"GameStop Corp.\"),\n",
    "        (\"AMC\", \"AMC Entertainment Holdings, Inc.\"),\n",
    "        (\"SPY\", \"SPDR S&P 500 ETF Trust\"),\n",
    "        (\"QQQ\", \"Invesco QQQ Trust\"),\n",
    "        (\"NFLX\", \"Netflix, Inc.\"),\n",
    "        (\"DIS\", \"The Walt Disney Company\"),\n",
    "        (\"UBER\", \"Uber Technologies, Inc.\"),\n",
    "        (\"PLTR\", \"Palantir Technologies Inc.\"),\n",
    "        (\"COIN\", \"Coinbase Global, Inc.\"),\n",
    "        (\"SHOP\", \"Shopify Inc.\"),\n",
    "    ]\n",
    "    \n",
    "    tickers = []\n",
    "    for symbol, name in mock_ticker_data:\n",
    "        mock_ticker = Mock(spec=Ticker)\n",
    "        mock_ticker.symbol = symbol\n",
    "        mock_ticker.name = name\n",
    "        tickers.append(mock_ticker)\n",
    "    \n",
    "    print(f\"âœ“ Created {len(tickers)} mock tickers for testing\")\n",
    "\n",
    "# Display first 10 tickers\n",
    "print(f\"\\nFirst 10 tickers:\")\n",
    "for ticker in tickers[:10]:\n",
    "    print(f\"  {ticker.symbol}: {ticker.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize TickerLinker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:jobs.ingest.linker:Built ticker symbol map with 40 entries (no aliases)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ TickerLinker initialized\n",
      "  Alias map size: 40 entries\n",
      "  Number of tickers: 20\n",
      "\n",
      "Sample alias mappings:\n",
      "  'war' -> WAR\n",
      "  'WAR' -> WAR\n",
      "  'tsla' -> TSLA\n",
      "  'TSLA' -> TSLA\n",
      "  'nvda' -> NVDA\n",
      "  'NVDA' -> NVDA\n",
      "  'msft' -> MSFT\n",
      "  'MSFT' -> MSFT\n",
      "  'v' -> V\n",
      "  'V' -> V\n"
     ]
    }
   ],
   "source": [
    "# Initialize the linker\n",
    "linker = TickerLinker(tickers, max_scraping_workers=5)\n",
    "\n",
    "print(f\"âœ“ TickerLinker initialized\")\n",
    "print(f\"  Alias map size: {len(linker.alias_to_ticker)} entries\")\n",
    "print(f\"  Number of tickers: {len(linker.tickers)}\")\n",
    "print(f\"\\nSample alias mappings:\")\n",
    "for i, (alias, symbol) in enumerate(list(linker.alias_to_ticker.items())[:10]):\n",
    "    print(f\"  '{alias}' -> {symbol}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Common Word Tickers Filter\n",
    "\n",
    "Check that common English words are in the filter list to prevent false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check some common word tickers (including newly added ones)\ntest_common_words = ['AI', 'GO', 'RUN', 'FAST', 'HOME', 'PLAY', 'WORK', 'V', 'A', 'T', 'WAR', 'BRO', 'LOT', 'FUN', 'YALL', 'WOW', 'SUB', 'TILL', 'TALK', 'EAT', 'COST', 'DIPS']\n\nprint(\"Common word ticker filter test:\")\nprint(\"These words require $ prefix OR (ALL CAPS + financial context):\\n\")\nfor word in test_common_words:\n    is_common = word in COMMON_WORD_TICKERS\n    symbol = \"âœ“\" if is_common else \"âœ—\"\n    status = \"COMMON WORD (strict rules)\" if is_common else \"Normal matching allowed\"\n    print(f\"  {symbol} {word:6s} : {status}\")\n\nprint(f\"\\nTotal common words in filter: {len(COMMON_WORD_TICKERS)}\")\n\n# Import and display the new CAPITALIZED_COMMON_WORDS list\nfrom jobs.ingest.linker import CAPITALIZED_COMMON_WORDS\nprint(f\"\\nCapitalized common words (ALWAYS require $): {CAPITALIZED_COMMON_WORDS}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Ticker Pattern Matching\n",
    "\n",
    "Test the `_find_ticker_matches` method with various text patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker Matching Tests:\n",
      "======================================================================\n",
      "\n",
      "1. Text: \"I love $AAPL and $TSLA stocks!\"\n",
      "   âœ“ Matches found:\n",
      "     â€¢ AAPL: ['AAPL', '$AAPL']\n",
      "     â€¢ TSLA: ['TSLA', '$TSLA']\n",
      "\n",
      "2. Text: \"Apple (AAPL) reported strong earnings.\"\n",
      "   âœ“ Matches found:\n",
      "     â€¢ AAPL: ['AAPL']\n",
      "\n",
      "3. Text: \"Tesla TSLA is performing well.\"\n",
      "   âœ“ Matches found:\n",
      "     â€¢ TSLA: ['TSLA']\n",
      "\n",
      "4. Text: \"$nvda and $amd are great semiconductor stocks\"\n",
      "   âœ“ Matches found:\n",
      "     â€¢ NVDA: ['$nvda', 'nvda']\n",
      "     â€¢ AMD: ['amd', '$amd']\n",
      "\n",
      "5. Text: \"I bought apples at the store (not the stock)\"\n",
      "   âœ— No matches found\n",
      "\n",
      "6. Text: \"Just got my visa application approved\"\n",
      "   âœ— No matches found\n",
      "\n",
      "7. Text: \"Visa Inc (V) stock is up 5% today\"\n",
      "   âœ— No matches found\n",
      "\n",
      "8. Text: \"$V is doing well in the market\"\n",
      "   âœ“ Matches found:\n",
      "     â€¢ V: ['$V']\n",
      "\n",
      "9. Text: \"Microsoft MSFT, Google GOOGL, and Amazon AMZN are tech giants\"\n",
      "   âœ“ Matches found:\n",
      "     â€¢ MSFT: ['MSFT']\n",
      "     â€¢ GOOGL: ['GOOGL']\n",
      "     â€¢ AMZN: ['AMZN']\n",
      "\n",
      "10. Text: \"The letter V is very common in English\"\n",
      "   âœ— No matches found\n"
     ]
    }
   ],
   "source": [
    "# Test cases for ticker matching\n",
    "test_texts = [\n",
    "    \"I love $AAPL and $TSLA stocks!\",\n",
    "    \"Apple (AAPL) reported strong earnings.\",\n",
    "    \"Tesla TSLA is performing well.\",\n",
    "    \"$nvda and $amd are great semiconductor stocks\",\n",
    "    \"I bought apples at the store (not the stock)\",\n",
    "    \"Just got my visa application approved\",\n",
    "    \"Visa Inc (V) stock is up 5% today\",\n",
    "    \"$V is doing well in the market\",\n",
    "    \"Microsoft MSFT, Google GOOGL, and Amazon AMZN are tech giants\",\n",
    "    \"The letter V is very common in English\",\n",
    "]\n",
    "\n",
    "print(\"Ticker Matching Tests:\\n\" + \"=\"*70)\n",
    "for i, text in enumerate(test_texts, 1):\n",
    "    matches = linker._find_ticker_matches(text)\n",
    "    print(f\"\\n{i}. Text: \\\"{text}\\\"\")\n",
    "    if matches:\n",
    "        print(f\"   âœ“ Matches found:\")\n",
    "        for ticker, terms in matches.items():\n",
    "            print(f\"     â€¢ {ticker}: {terms}\")\n",
    "    else:\n",
    "        print(f\"   âœ— No matches found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Article Linking with Context Analysis\n",
    "\n",
    "Create test articles and link them to tickers using the full linking pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test articles\n",
    "test_articles = [\n",
    "    # Clear ticker mention with $\n",
    "    Article(\n",
    "        source=\"test\",\n",
    "        url=\"https://example.com/1\",\n",
    "        published_at=datetime.now(UTC),\n",
    "        title=\"Apple Stock Soars\",\n",
    "        text=\"Apple stock $AAPL is up 5% today after strong iPhone sales.\"\n",
    "    ),\n",
    "    \n",
    "    # Multiple tickers\n",
    "    Article(\n",
    "        source=\"test\",\n",
    "        url=\"https://example.com/2\",\n",
    "        published_at=datetime.now(UTC),\n",
    "        title=\"Tech Stocks Rally\",\n",
    "        text=\"$AAPL, $MSFT, and $GOOGL all saw gains today in the tech sector.\"\n",
    "    ),\n",
    "    \n",
    "    # Ticker without $ but with financial context\n",
    "    Article(\n",
    "        source=\"test\",\n",
    "        url=\"https://example.com/3\",\n",
    "        published_at=datetime.now(UTC),\n",
    "        title=\"Tesla Earnings Beat Expectations\",\n",
    "        text=\"Tesla TSLA stock surged after the company reported quarterly earnings that beat analyst expectations.\"\n",
    "    ),\n",
    "    \n",
    "    # Ambiguous - should not match (visa application, not Visa Inc)\n",
    "    Article(\n",
    "        source=\"test\",\n",
    "        url=\"https://example.com/4\",\n",
    "        published_at=datetime.now(UTC),\n",
    "        title=\"Visa Application Process\",\n",
    "        text=\"The visa application process has been simplified. You can now apply for a visa online.\"\n",
    "    ),\n",
    "    \n",
    "    # Clear Visa Inc mention with $\n",
    "    Article(\n",
    "        source=\"test\",\n",
    "        url=\"https://example.com/5\",\n",
    "        published_at=datetime.now(UTC),\n",
    "        title=\"Visa Inc Earnings\",\n",
    "        text=\"Visa Inc $V reported strong quarterly revenue growth driven by increased payment volume.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(f\"âœ“ Created {len(test_articles)} test articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link articles to tickers\n",
    "print(\"\\nArticle Linking Results:\\n\" + \"=\"*80)\n",
    "\n",
    "for i, article in enumerate(test_articles, 1):\n",
    "    ticker_links = linker.link_article(article, use_title_only=False)\n",
    "    \n",
    "    print(f\"\\n{i}. Article: {article.title}\")\n",
    "    print(f\"   Text: {article.text[:80]}...\")\n",
    "    \n",
    "    if ticker_links:\n",
    "        print(f\"   âœ“ Linked to {len(ticker_links)} ticker(s):\")\n",
    "        for link in ticker_links:\n",
    "            print(f\"     â€¢ {link.ticker}\")\n",
    "            print(f\"       - Confidence: {link.confidence:.2f}\")\n",
    "            print(f\"       - Matched terms: {', '.join(link.matched_terms)}\")\n",
    "            print(f\"       - Reasoning: {', '.join(link.reasoning)}\")\n",
    "    else:\n",
    "        print(f\"   âœ— No tickers linked (below confidence threshold)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Reddit Comment Fast Path\n",
    "\n",
    "Test the optimized fast path for Reddit comments (skips context analysis for speed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Comment Fast Path Tests:\n",
      "================================================================================\n",
      "\n",
      "1. Comment: *Reported* homicides. Truth is the first casualty of war. And our govt. is at war with its citizens.\n",
      "   âœ— No tickers linked\n"
     ]
    }
   ],
   "source": [
    "# Create Reddit comment test articles\n",
    "reddit_comments = [\n",
    "    Article(\n",
    "        source=\"reddit_comment\",\n",
    "        url=\"https://reddit.com/comment/4\",\n",
    "        published_at=datetime.now(UTC),\n",
    "        title=\"Comment 4\",\n",
    "        text=\"*Reported* homicides. Truth is the first casualty of war. And our govt. is at war with its citizens.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"Reddit Comment Fast Path Tests:\\n\" + \"=\"*80)\n",
    "\n",
    "for i, comment in enumerate(reddit_comments, 1):\n",
    "    # This should use the fast path\n",
    "    ticker_links = linker.link_article(comment)\n",
    "    \n",
    "    print(f\"\\n{i}. Comment: {comment.text}\")\n",
    "    \n",
    "    if ticker_links:\n",
    "        print(f\"   âœ“ Linked to {len(ticker_links)} ticker(s):\")\n",
    "        for link in ticker_links:\n",
    "            print(f\"     â€¢ {link.ticker}: {link.confidence:.2f} confidence ({', '.join(link.matched_terms)})\")\n",
    "    else:\n",
    "        print(f\"   âœ— No tickers linked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Edge Cases\n",
    "\n",
    "Test various edge cases and potential false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "edge_cases = [\n    # Single letter ticker without $ (should NOT match)\n    Article(\n        source=\"test\",\n        url=\"https://example.com/edge1\",\n        published_at=datetime.now(UTC),\n        title=\"Letter V\",\n        text=\"The letter V is very common in English.\"\n    ),\n    \n    # Single letter ticker with $ (SHOULD match)\n    Article(\n        source=\"test\",\n        url=\"https://example.com/edge2\",\n        published_at=datetime.now(UTC),\n        title=\"Visa Stock\",\n        text=\"I'm buying $V today. Visa is a strong company.\"\n    ),\n    \n    # Common word ticker without $ and no financial context (should NOT match)\n    Article(\n        source=\"test\",\n        url=\"https://example.com/edge3\",\n        published_at=datetime.now(UTC),\n        title=\"Fast Cars\",\n        text=\"I love fast cars and going on road trips.\"\n    ),\n    \n    # Mixed case tickers (should normalize)\n    Article(\n        source=\"test\",\n        url=\"https://example.com/edge4\",\n        published_at=datetime.now(UTC),\n        title=\"Tech Stocks\",\n        text=\"Looking at $aapl, $Msft, and $GOOGL for my portfolio.\"\n    ),\n    \n    # Empty text (should not crash)\n    Article(\n        source=\"test\",\n        url=\"https://example.com/edge5\",\n        published_at=datetime.now(UTC),\n        title=\"\",\n        text=\"\"\n    ),\n    \n    # Ticker as part of URL (should still match if $ prefix)\n    Article(\n        source=\"test\",\n        url=\"https://example.com/edge6\",\n        published_at=datetime.now(UTC),\n        title=\"Investment Discussion\",\n        text=\"Check out $PLTR and $COIN - both have huge potential!\"\n    ),\n    \n    # NEW TEST: WAR in lowercase context (should NOT match)\n    Article(\n        source=\"test\",\n        url=\"https://example.com/edge7\",\n        published_at=datetime.now(UTC),\n        title=\"War Discussion\",\n        text=\"The war on drugs has been going on for decades.\"\n    ),\n    \n    # NEW TEST: WAR in ALL CAPS with financial context (SHOULD match)\n    Article(\n        source=\"test\",\n        url=\"https://example.com/edge8\",\n        published_at=datetime.now(UTC),\n        title=\"ETF Analysis\",\n        text=\"Looking at WAR stock performance, the ETF has shown strong gains this quarter.\"\n    ),\n    \n    # NEW TEST: WAR with $ prefix (SHOULD match)\n    Article(\n        source=\"test\",\n        url=\"https://example.com/edge9\",\n        published_at=datetime.now(UTC),\n        title=\"ETF Discussion\",\n        text=\"I'm considering buying $WAR for my portfolio.\"\n    ),\n    \n    # NEW TEST: Multiple common words in lowercase (should NOT match)\n    Article(\n        source=\"test\",\n        url=\"https://example.com/edge10\",\n        published_at=datetime.now(UTC),\n        title=\"Food Talk\",\n        text=\"I love to eat good food and talk with my bro about fun stuff. The cost is worth it till we're done.\"\n    ),\n    \n    # NEW TEST: Multiple common words in ALL CAPS with financial context (SHOULD match if they're tickers)\n    Article(\n        source=\"test\",\n        url=\"https://example.com/edge11\",\n        published_at=datetime.now(UTC),\n        title=\"Stock Portfolio\",\n        text=\"My stock portfolio includes FUN and COST. Both stocks have shown solid earnings growth.\"\n    ),\n    \n    # NEW TEST: Letter A at start of sentence (should NOT match)\n    Article(\n        source=\"test\",\n        url=\"https://example.com/edge12\",\n        published_at=datetime.now(UTC),\n        title=\"General Discussion\",\n        text=\"A great opportunity is emerging in the market.\"\n    ),\n    \n    # NEW TEST: Letter I in sentence (should NOT match)\n    Article(\n        source=\"test\",\n        url=\"https://example.com/edge13\",\n        published_at=datetime.now(UTC),\n        title=\"Personal Opinion\",\n        text=\"I think the market will continue to grow.\"\n    ),\n    \n    # NEW TEST: $A and $I with dollar sign (SHOULD match)\n    Article(\n        source=\"test\",\n        url=\"https://example.com/edge14\",\n        published_at=datetime.now(UTC),\n        title=\"Ticker Discussion\",\n        text=\"Looking at $A and $I for potential investments.\"\n    ),\n]\n\nprint(\"Edge Case Tests:\\n\" + \"=\"*80)\n\nfor i, article in enumerate(edge_cases, 1):\n    ticker_links = linker.link_article(article, use_title_only=False)\n    \n    print(f\"\\n{i}. Title: {article.title or '(empty)'}\")\n    print(f\"   Text: {article.text[:60] if article.text else '(empty)'}...\")\n    \n    if ticker_links:\n        print(f\"   âœ“ Linked to {len(ticker_links)} ticker(s):\")\n        for link in ticker_links:\n            print(f\"     â€¢ {link.ticker}: {link.confidence:.2f}\")\n    else:\n        print(f\"   âœ— No tickers linked\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Batch Processing Test\n",
    "\n",
    "Test linking multiple articles at once and gather statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all test articles\n",
    "all_articles = test_articles + reddit_comments + edge_cases\n",
    "\n",
    "print(f\"Batch processing {len(all_articles)} articles...\\n\")\n",
    "\n",
    "# Link all articles\n",
    "results = linker.link_articles(all_articles)\n",
    "\n",
    "# Calculate statistics\n",
    "total_links = sum(len(links) for _, links in results)\n",
    "linked_articles = sum(1 for _, links in results if links)\n",
    "avg_confidence = sum(link.confidence for _, links in results for link in links) / total_links if total_links > 0 else 0\n",
    "\n",
    "print(\"\\nBatch Processing Summary:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total articles processed: {len(all_articles)}\")\n",
    "print(f\"Articles with ticker links: {linked_articles}\")\n",
    "print(f\"Articles without links: {len(all_articles) - linked_articles}\")\n",
    "print(f\"Total ticker links created: {total_links}\")\n",
    "print(f\"Average links per article: {total_links/len(all_articles):.2f}\")\n",
    "print(f\"Average confidence score: {avg_confidence:.2f}\")\n",
    "\n",
    "# Show distribution of confidence scores\n",
    "if total_links > 0:\n",
    "    all_confidences = [link.confidence for _, links in results for link in links]\n",
    "    print(f\"\\nConfidence Distribution:\")\n",
    "    print(f\"  Min: {min(all_confidences):.2f}\")\n",
    "    print(f\"  Max: {max(all_confidences):.2f}\")\n",
    "    print(f\"  Avg: {avg_confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Performance Testing\n",
    "\n",
    "Test the performance of the linking system with a larger batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Create a larger batch of test articles\n",
    "performance_articles = []\n",
    "test_patterns = [\n",
    "    \"$AAPL is up today\",\n",
    "    \"$TSLA reported strong earnings\",\n",
    "    \"$NVDA and $AMD are both rising\",\n",
    "    \"Microsoft $MSFT announced new products\",\n",
    "    \"Google stock $GOOGL surged after hours\",\n",
    "]\n",
    "\n",
    "for i in range(50):\n",
    "    pattern = test_patterns[i % len(test_patterns)]\n",
    "    performance_articles.append(\n",
    "        Article(\n",
    "            source=\"test\",\n",
    "            url=f\"https://example.com/perf{i}\",\n",
    "            published_at=datetime.now(UTC),\n",
    "            title=f\"Test Article {i}\",\n",
    "            text=f\"This is test article {i}. {pattern}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(f\"Performance test with {len(performance_articles)} articles...\\n\")\n",
    "\n",
    "# Time the linking process\n",
    "start_time = time.time()\n",
    "perf_results = linker.link_articles(performance_articles)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed = end_time - start_time\n",
    "per_article = elapsed / len(performance_articles)\n",
    "\n",
    "print(\"\\nPerformance Results:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total time: {elapsed:.2f} seconds\")\n",
    "print(f\"Time per article: {per_article*1000:.2f} ms\")\n",
    "print(f\"Articles per second: {len(performance_articles)/elapsed:.2f}\")\n",
    "\n",
    "# Calculate success rate\n",
    "successful_links = sum(1 for _, links in perf_results if links)\n",
    "print(f\"\\nLinking success rate: {successful_links/len(performance_articles)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Real Database Articles Test (Optional)\n",
    "\n",
    "Test linking with actual articles from the database (only runs if `USE_DATABASE = True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_DATABASE and session:\n",
    "    # Get some real articles from the database\n",
    "    real_articles = session.query(Article).limit(10).all()\n",
    "    \n",
    "    if real_articles:\n",
    "        print(f\"Testing with {len(real_articles)} real articles from database:\\n\" + \"=\"*80)\n",
    "        \n",
    "        for i, article in enumerate(real_articles, 1):\n",
    "            ticker_links = linker.link_article(article, use_title_only=False)\n",
    "            \n",
    "            print(f\"\\n{i}. Source: {article.source}\")\n",
    "            print(f\"   Title: {article.title[:60] if article.title else '(no title)'}...\")\n",
    "            print(f\"   URL: {article.url[:50]}...\")\n",
    "            \n",
    "            if ticker_links:\n",
    "                print(f\"   âœ“ Linked to {len(ticker_links)} ticker(s):\")\n",
    "                for link in ticker_links:\n",
    "                    print(f\"     â€¢ {link.ticker}: {link.confidence:.2f} ({', '.join(link.matched_terms[:3])})\")\n",
    "            else:\n",
    "                print(f\"   âœ— No tickers linked\")\n",
    "    else:\n",
    "        print(\"No articles found in database\")\n",
    "else:\n",
    "    print(\"Skipping database test (USE_DATABASE = False)\")\n",
    "    print(\"\\nTo test with real database articles:\")\n",
    "    print(\"  1. Set USE_DATABASE = True in the first cell\")\n",
    "    print(\"  2. Restart the notebook and run all cells\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Test Specific Linker Methods\n",
    "\n",
    "Test individual methods directly for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test _fast_reddit_comment_linking directly\n",
    "print(\"Testing _fast_reddit_comment_linking method:\\n\" + \"=\"*60)\n",
    "\n",
    "test_comment = Article(\n",
    "    source=\"reddit_comment\",\n",
    "    url=\"https://reddit.com/test\",\n",
    "    published_at=datetime.now(UTC),\n",
    "    title=\"Test Comment\",\n",
    "    text=\"ðŸš€ðŸš€ðŸš€ $GME $AMC to the moon! YOLO! ðŸ’ŽðŸ™Œ\"\n",
    ")\n",
    "\n",
    "fast_results = linker._fast_reddit_comment_linking(test_comment)\n",
    "\n",
    "print(f\"Comment: {test_comment.text}\")\n",
    "print(f\"\\nResults from fast path:\")\n",
    "for link in fast_results:\n",
    "    print(f\"  â€¢ {link.ticker}: {link.confidence:.2f}\")\n",
    "    print(f\"    Matched: {link.matched_terms}\")\n",
    "    print(f\"    Reasoning: {link.reasoning}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test _extract_text_for_matching method\n",
    "print(\"Testing _extract_text_for_matching method:\\n\" + \"=\"*60)\n",
    "\n",
    "test_article = Article(\n",
    "    source=\"test\",\n",
    "    url=\"https://example.com/test\",\n",
    "    published_at=datetime.now(UTC),\n",
    "    title=\"Test Article Title\",\n",
    "    text=\"This is the article body text with $AAPL mention.\"\n",
    ")\n",
    "\n",
    "extracted_text = linker._extract_text_for_matching(test_article, use_title_only=True)\n",
    "print(f\"Article title: {test_article.title}\")\n",
    "print(f\"Article text: {test_article.text}\")\n",
    "print(f\"\\nExtracted text (title_only=True):\")\n",
    "print(f\"  {extracted_text}\")\n",
    "\n",
    "extracted_full = linker._extract_text_for_matching(test_article, use_title_only=False)\n",
    "print(f\"\\nExtracted text (title_only=False):\")\n",
    "print(f\"  {extracted_full}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database session if it was opened\n",
    "if USE_DATABASE and session:\n",
    "    session.close()\n",
    "    print(\"âœ“ Database session closed\")\n",
    "else:\n",
    "    print(\"âœ“ No database session to close (using mock data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook tested the following linking module functions:\n",
    "\n",
    "### Functions Tested:\n",
    "\n",
    "1. **`TickerLinker.__init__()`** - Initialization with tickers\n",
    "2. **`TickerLinker._build_alias_map()`** - Building ticker symbol mapping\n",
    "3. **`TickerLinker._find_ticker_matches()`** - Pattern matching for tickers in text\n",
    "4. **`TickerLinker._extract_text_for_matching()`** - Text extraction from articles\n",
    "5. **`TickerLinker._fast_reddit_comment_linking()`** - Fast path for Reddit comments\n",
    "6. **`TickerLinker.link_article()`** - Main linking method with context analysis\n",
    "7. **`TickerLinker.link_articles()`** - Batch processing of multiple articles\n",
    "\n",
    "### Key Features Tested:\n",
    "\n",
    "- âœ“ **$TICKER format matching** (high confidence - 0.9)\n",
    "- âœ“ **TICKER format matching** (medium confidence - 0.7)\n",
    "- âœ“ **Common word filtering** (prevents false positives like \"I\", \"AI\", \"GO\")\n",
    "- âœ“ **Single letter ticker handling** (requires $ prefix)\n",
    "- âœ“ **Context analysis integration** (confidence scoring)\n",
    "- âœ“ **Reddit comment optimization** (fast path without heavy analysis)\n",
    "- âœ“ **Confidence scoring** (0.5 minimum threshold)\n",
    "- âœ“ **Matched terms tracking** (shows what triggered the match)\n",
    "- âœ“ **Edge cases** (empty text, mixed case, ambiguous mentions)\n",
    "- âœ“ **Performance benchmarking** (articles per second)\n",
    "\n",
    "### Testing Modes:\n",
    "\n",
    "- **Mock Mode** (`USE_DATABASE = False`): Tests with 20 mock tickers, no DB required\n",
    "- **Database Mode** (`USE_DATABASE = True`): Tests with real tickers and articles from DB\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Run with real database to test integration\n",
    "- Adjust confidence thresholds if needed\n",
    "- Add more common words to filter if false positives occur\n",
    "- Monitor performance with larger datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}